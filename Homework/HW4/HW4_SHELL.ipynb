{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCE 623 SP 2020 Assignment 4\n",
    "## LASTNAME, FIRSTNAME\n",
    "## YYYYMMDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import copy\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part A:  Data setup and exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1:  Load, clean, split, explore, and transform the data to prepare it for machine learning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('ISLR_Hitters.csv', index_col=0).dropna()\n",
    "df.index.name = 'Player'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the names of the features\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data\n",
    "1. Separate the prediction (y) from the features (X)\n",
    "1. League, Division and NewLeague are categories which should be converted to dummy (on-hot) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y = df.Salary\n",
    "\n",
    "# create the dummy variables\n",
    "dummies = pd.get_dummies(df[['League', 'Division', 'NewLeague']])\n",
    "dummies.info()  #confirm existence of dummies and auto-generated names\n",
    "\n",
    "# Drop the column with the independent variable (Salary), and columns for which we created dummy variables from categorical features\n",
    "X_ = df.drop(['Salary', 'League', 'Division', 'NewLeague'], axis=1).astype('float64')\n",
    "\n",
    "\n",
    "#since each dummy includes only 2 categories, use a single category to encode all info\n",
    "X = pd.concat([X_, dummies[['League_N', 'Division_W', 'NewLeague_N']]], axis=1)\n",
    "\n",
    "\n",
    "X.info()  #confirm existence of dummies and auto-generated names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into test and non-test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nonTest, X_test, y_nonTest, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data & make prediction about features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0  Data exploration\n",
    "Note that exploration can be done on the non-scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nonTest.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nonTest.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nonTest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that the categorical variable conversion to 1-hot features worked - and explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nonTest.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when exploring relationship between features and predictors, use a combined set\n",
    "xy_nontest = pd.concat([X_nonTest, y_nonTest], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE - THIS MAKE TAKE A FEW MOMENTS TO CALCULATE & DISPLAY ON YOUR COMPUTER\n",
    "\n",
    "#switch the below to True to show the pairsplot.\n",
    "if False:\n",
    "    sns.pairplot(xy_nontest)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation plot to help features which might be encoding the same information\n",
    "# magnitude is important: features close to 1 or close to -1 are more correlated with each other\n",
    "\n",
    "corr = xy_nontest.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of Top-6 Features\n",
    "List the features that you think will be most important for predicting salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STUDENT ANSWER:  INSERT YOUR HYPOTHESIS HERE \n",
    "\n",
    "\n",
    "END STUDENT ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale all X data using nonTest data scaler\n",
    "* Scale the data features since we dont want some features to affect the linear regressions differently just becasue they have different scales\n",
    "* Fit the scaler to the non-test data then apply those fitted parameters to the test data to preserve the scaling without being influenced by any aspect of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_nonTest) # once we fit a scaler to the non-test data it can be used later to scale the test data without looking at the test data\n",
    "X_nonTestScaled = pd.DataFrame(scaler.transform(X_nonTest), columns=X_nonTest.columns)  #non-test data scaled using non-test data mean and var\n",
    "X_testScaled = scaler.transform(X_test)   #test data scaled using non-test data mean and var (prevents \"learning\" about the test set)\n",
    "\n",
    "print(X_nonTest.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Explore, then Scale the Y data using a an exponential scaler\n",
    "notice that the original Y values are very non-normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_nonTest,bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The response variable, Salary, was noticed to have a non-normal distribution. Using this heavily skewed distribution could negatively affect any model-fitting using a least-squares based regression due to the assumption of normality required on the error term. Therefore, a natural log transform was performed on Salary, yielding a distribution that, while not perfectly normal, is much less heavily skewed and more likely to not violate the normally distributed error assumption. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nonTestScaled = np.log(y_nonTest)\n",
    "plt.hist(y_nonTestScaled,bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the new Y values after scaling are not as skewed, they are still not \"normally distributed\"\n",
    "\n",
    "Next, build a helper function to compute MSE on predictions in the logspace.  This MSE method will be used by our model while computing the optimization equiation in search for good parameters.\n",
    "A transform to calculate the $MSE$ in the original dataspace is shown below - and all $MSE$ values are reported in this space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_mse(y_true, y_pred):\n",
    "    ydiff = np.exp(y_true) - np.exp(y_pred)\n",
    "    mse = np.dot(ydiff.T, ydiff)/len(ydiff)\n",
    "    return mse\n",
    "\n",
    "dataspace_mse = make_scorer(transform_mse, greater_is_better=False)  #this scorer can be used by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part B:  Best Subset Selection: Determining the *Best* model features for each size linear regression model\n",
    "\n",
    "Note:  set the number of features to 3 here to reduce run time during testing.  Setting higher will take significantly longer.\n",
    "setting runtimes will be longer than picking num_features=3 by approximately:\n",
    "* 4: 4x longer\n",
    "* 5: 12x longer\n",
    "* 6: 28x longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 3   #  Only increase this beyond 3 if you have time to wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2:  Write Function For Best-Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestSubset(X_nonTest,y_nonTest, k):\n",
    "    kfeatures = []  #placeholder\n",
    "    kMSE = 1e8  #placeholder\n",
    "    \n",
    "    ##########################\n",
    "    # INSERT STUDENT CODE HERE\n",
    "    \n",
    "   \n",
    "    # END STUDENT CODE\n",
    "    ##########################\n",
    "    \n",
    "    return kfeatures, kMSE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3:  Execute best subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# INSERT STUDENT CODE HERE\n",
    "\n",
    "\n",
    "    \n",
    "# END STUDENT CODE\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4:  Plot of Avg Crossval MSE for 6 best models with annotated best point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# INSERT STUDENT CODE HERE\n",
    "\n",
    "\n",
    "# END STUDENT CODE\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 5:  Discussion of best subset models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STUDENT RESPONSE BELOW:\n",
    "\n",
    "\n",
    "END STUDENT REPONSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 6:  Write Function For Forward Stepwise Subset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardStepwiseSubset(X_nonTest,y_nonTest, k):\n",
    "    kfeatures = []  #placeholder\n",
    "    kMSE = []  #placeholder\n",
    "    \n",
    "    ##########################\n",
    "    # INSERT STUDENT CODE HERE\n",
    "    \n",
    "    \n",
    "    # END STUDENT CODE\n",
    "    ##########################\n",
    "    \n",
    "    return (kfeatures, kMSE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 7:  Execute Forward subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# INSERT STUDENT CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# END STUDENT CODE\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 8:  Updated Plot of Avg Crossval MSE & best points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# INSERT STUDENT CODE HERE\n",
    "\n",
    "\n",
    "# END STUDENT CODE\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 9:  Discussion of best foward-stepwise models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STUDENT RESPONSE BELOW:\n",
    "\n",
    "\n",
    "\n",
    "END STUDENT REPONSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 10: Discussion and comparison of subset selection methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STUDENT RESPONSE BELOW:\n",
    "\n",
    "\n",
    "\n",
    "END STUDENT REPONSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 11: Write a function to execute LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LASSOSubset(X_nonTest,y_nonTest, k):\n",
    "    #example of logarithmically spaced alphas for LASSO... may need tweaking\n",
    "    alphas = np.logspace(-3, 10,num=300)\n",
    "    kfeatures = [] #placeholder\n",
    "    kMSE=np.inf  #placeholder\n",
    "    kalpha = 0  #placeholder\n",
    "\n",
    "    ##########################\n",
    "    # INSERT STUDENT CODE HERE\n",
    "\n",
    "\n",
    "\n",
    "    # END STUDENT CODE\n",
    "    ##########################\n",
    "        \n",
    "    return (kfeatures, kMSE, kalpha)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 12: Execute LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# INSERT STUDENT CODE HERE\n",
    "\n",
    "    \n",
    "# END STUDENT CODE\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 13: Updated Plot of Avg Crossval MSE & best points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "# INSERT STUDENT CODE HERE\n",
    "\n",
    "\n",
    "# END STUDENT CODE\n",
    "##########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 14: Discussion of best foward-stepwise models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STUDENT RESPONSE BELOW:\n",
    "\n",
    "\n",
    "END STUDENT REPONSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 15: Answer Customer Questions\n",
    "\n",
    "## a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STUDENT RESPONSE BELOW:\n",
    "\n",
    "\n",
    "END STUDENT REPONSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STUDENT RESPONSE BELOW:\n",
    "\n",
    "\n",
    "\n",
    "END STUDENT REPONSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END OF ASSIGNMENT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
