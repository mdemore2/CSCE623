{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1dd6c101f81a68ffa12ed4775a05db73",
     "grade": false,
     "grade_id": "cell-6d0fb40523026b17",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Simple Linear Regression\n",
    "===\n",
    "In-Class Active Learning Activity\n",
    "Learning Goals:\n",
    "* Practice using numpy to instantiate and peform operations on arrays\n",
    "* Encode a one-feature dataset as a design matrix\n",
    "* Develop a simple linear regression parameterized model which estimates values based on hand-picked parameter values\n",
    "* Compute the error terms per observation and the aggregate errors for the set of observations\n",
    "* Iteratively repeat the process of selecting better parameters by hand to improve the model\n",
    "* Plot the datapoints using matplotlib to display the output\n",
    "* Plot a line through the data representing a paramaterized linear regression solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "264c86d84d43d3154c1ed2d55a1c2454",
     "grade": false,
     "grade_id": "cell-c94e45c1c49bc83a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9db6442facade56bf013b53862982e79",
     "grade": false,
     "grade_id": "cell-d76293ddc6bd657d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Below is a simple dataset with 5 students' scores on an pretest (this set of scores is known as an attibute or *feature* and is shown in column X1), and their resulting scores on a course final exam (this is what we will eventually try to predict - we refer to this as the *label* y).  Your goal is to build a simple linear regression model (by hand) which predicts y based on X1.  You will hand-pick values for 2 coefficients ($\\beta_0$ and $\\beta_1$) to try to minimize the prediction errors so your model fits well.  Then you will use a graph to display the best line through the data.  Note that $\\beta_0$ is the y-intercept and $\\beta_1$ is the effect of the aptitude test (X1) on the slope of the line.\n",
    "\n",
    "| Student (i) | X1 | y  |\n",
    "|-------------|----|----|\n",
    "| 1           | 95 | 85 |\n",
    "| 2           | 85 | 95 |\n",
    "| 3           | 80 | 70 |\n",
    "| 4           | 70 | 65 |\n",
    "| 5           | 60 | 70 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "16ea5301bc3817a7a7561463fb79eeef",
     "grade": false,
     "grade_id": "cell-79792a9830cabec6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now build this dataset of features and labels\n",
    "\n",
    "STUDENT CODE - insert code to hardcode your 5 row x 1 column matrix for X1 (```pretest_scores```) and 5 row x 1 column matrix for final exam scores (```y```) here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa433127df16934b64ad0c782cbf929d",
     "grade": false,
     "grade_id": "cell-17e0eec41251a5e8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------    \n",
    "pretest_scores = np.array([ ]).T  #(5x1 array) you populate\n",
    "y = np.array([[ ]]).T  #(5x1 array) you populate\n",
    "#---------------------------------------------    \n",
    "\n",
    "# insert code to load your matrix here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8b30b4fa95e2b30ade351519a37cbe84",
     "grade": false,
     "grade_id": "cell-f182f101c8998496",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Consider the following generalized equation for linear regression for estimating the regression value when an observation has one feature:\n",
    "\n",
    "\n",
    "$$\\hat y_i=f(X_i )=\\beta_0+\\beta_1 X_{i,1}$$\n",
    "\n",
    "where $X_{i,1}$ is the feature value for the $i$'th observation\n",
    "\n",
    "if, using identity, we multiply each of the terms on the right hand side by $1$ then we get this:\n",
    "\n",
    "$$\\hat y_i=\\beta_0 \\cdot 1+\\beta_1 X_{i,1} \\cdot 1$$\n",
    "\n",
    "which could be rewritten by introducting a *dummy variable*: $\\forall i, X_{i,0}=1 $:\n",
    "\n",
    "$$\\hat y_i=\\beta_0 \\cdot X_{i,0}+\\beta_1 X_{i,1} \\cdot 1$$\n",
    "\n",
    "where $X_{i,0}$ is always $1$.  Then, by dividing the last term by $1$, more simply:\n",
    "\n",
    "$$\\hat y_i=\\beta_0 \\cdot X_{i,0}+\\beta_1 X_{i,1}$$\n",
    "\n",
    "or in matrix multiplication form:\n",
    "\n",
    "$$\\hat y= X \\cdot \\beta^\\intercal$$\n",
    "\n",
    "where $\\hat y$ is a column vector with as many rows as observations, $\\beta$ is a row vector with the column count one more than the number of features (1+1 = 2) and $X$ is a *design matrix* with as many rows as observations and the column count is one more than the number of features. \n",
    "\n",
    "\n",
    "To implement the computation of $\\hat y$ in code we need both $X$ and $\\beta$.   \n",
    "\n",
    "The next code chunk implements the design matrix ```X``` shown below: \n",
    "\n",
    "| 1 | 95 |\n",
    "|---|----|\n",
    "| 1 | 85 |\n",
    "| 1 | 80 |\n",
    "| 1 | 70 |\n",
    "| 1 | 60 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a68edd222695e69b0f2de3bca34d1780",
     "grade": false,
     "grade_id": "cell-5d540cc84cb1fee5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#build the design matrix X from pretest_scores\n",
    "X = np.vstack((np.ones(len(pretest_scores)),pretest_scores)).T  \n",
    "print('design matrix X:', '\\n', X, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "899f3e1ed4daf74e6b9b7e1e9308d2df",
     "grade": false,
     "grade_id": "cell-04fc4f77c139f1ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In the next few steps in python, you will implement a matrix to hold yoru guess for $\\beta$ (```beta```), and the code required to perform the matrix multiplication which produces the (guessed) vector $\\hat y$ (```yhat```)   Note that you will need to pick the initial values for  ```beta```.  These two beta values are the $y$-intercept and slope of the line (remember your grade school math?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6f5f253bf7e1d8dc90d7e4e5d33e0bbb",
     "grade": false,
     "grade_id": "cell-20a9f495862693ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "\n",
    "STUDENT CODE - Insert code for your ```beta``` guess here.  This should be a 1x2 numpy array:  $[[\\beta_0, \\beta_1]]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76d30fb9059542bff5d61f0d2ea32750",
     "grade": false,
     "grade_id": "cell-3b2c46cd73c9d6ae",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#---------------------------------------------          \n",
    "beta = np.array([[ ]])    #guess the betas (1x2 array) you populate: Beta_0 and Beta_1 \n",
    "#---------------------------------------------      \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d70cb9066d46ede620a215da9fcfdab8",
     "grade": false,
     "grade_id": "cell-ddd65cfe1824c824",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#print the Betas and X's\n",
    "print('Beta','\\n', beta, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "901af245427b8ceeeac170d20c1f62ff",
     "grade": false,
     "grade_id": "cell-366c41d9cedd94f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that you have selected some guessed parameters for the model, lets see what they would look like on a plot.  You might not be happy with your line, and you might be tempted to change your ```beta``` values now... but lets hold off on that for a bit so we can do it more scientifically later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "992d0dec812369a4027d1b53fd884c36",
     "grade": false,
     "grade_id": "cell-76697de15e909e28",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#function to generate line points for plotting\n",
    "def computeline(intercept,slope,start_x,end_x):\n",
    "    points_x=[start_x,end_x]\n",
    "    points_y=[intercept,intercept+slope*end_x]\n",
    "    return points_x, points_y\n",
    "\n",
    "def generate_plot(X,y,betas, linelabels=[\"beta predicted line\"], prevfig=None):\n",
    "    ''' Accepts a list of betas and a list of linelabels - enclose elements in brackets when calling'''\n",
    "    #make the figure\n",
    "    if prevfig == None:\n",
    "        fig = plt.figure()\n",
    "        \n",
    "    else:\n",
    "        fig = prevfig\n",
    "        \n",
    "    plt.axis([0.,100.,0.,100.])\n",
    "\n",
    "    #add the points in black\n",
    "    plt.scatter(X[:,1],y,c='k',marker='x', label = \"training datapoints\")\n",
    "\n",
    "\n",
    "    #add the student line in blue\n",
    "    for beta, linelabel in zip(betas,linelabels):\n",
    "        #print(beta, linelabel)\n",
    "        #print(beta[0,0],beta[0,1])\n",
    "        points_x,points_y = computeline(beta[0,0],beta[0,1],0,100)\n",
    "        plt.plot(points_x,points_y, label = linelabel)\n",
    "\n",
    "    plt.title('Simple Regression')\n",
    "    plt.ylabel('Final Exam Score')\n",
    "    plt.xlabel('Aptitude test score')\n",
    "    plt.axis('equal')\n",
    "    plt.grid(True)\n",
    "    #     plt.legend([linelabel,\"training datapoints\"])\n",
    "    plt.legend()\n",
    "    return fig\n",
    "    \n",
    "myfig = generate_plot(X,y,[beta],[\"initial guess beta\"])\n",
    "\n",
    "# myfig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdc20468190b1586c9a4ad9b36e9329c",
     "grade": false,
     "grade_id": "cell-cfba6370981f4d3e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Ok - so we can see our ```beta```-defined line (however bad it may be).  While this gives us a visual cue on how to improve our models performance (e.g. slide the line up or down, increase or decresase the slope,) it doesn't really reveal how good or bad the model would perform compared to other models.  So lets look at some quantitative methods of evaluating our model.\n",
    "\n",
    "In this next stage we will implement a parameterized *linear regression* model (with parameters $\\beta_0$ and $\\beta_1$ you selected earlier) to *estimate* what the values of y would be for each of those students.   Note that we actually have *truth data* in the labels (```y```) for each observation, but the linear regression model's parameters will likely give us different predictions.  We can then use these difference between estimations and actuals to quantitatively evaluate and improve our model.\n",
    "\n",
    "The steps are:\n",
    "* Implement a simple linear regression model using ```beta``` to compute an estimate of ```y``` (known as ```yhat```) given a pretest score\n",
    "* Use the model to make estimates for all of the final exam scores for all students\n",
    "* Determine the residuals for all students's final exam scores\n",
    "* Compute several performance measures for the model such that these performance measures could allow comparisons with other models\n",
    "* Guess a better ```beta``` and reevaluate the model... repeating the process until we are happy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a67c88e515c8da79f21b19fc196ced4f",
     "grade": false,
     "grade_id": "cell-c975e2ff504603a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, you will write code to implement the matrix equation ($\\hat y=\\beta \\cdot X$) for computing ```y``` (which is a vector of length 5), from $\\beta$ (which is a vector of length 2), and $X$ (which is a 5 x 2 matrix).  You will do this inside of a function called ```estimate``` which requires two values - ```beta``` and ```X```\n",
    "\n",
    "STUDENT CODE - Within the function ```estimate```, use ```numpy's``` ```dot()``` function to perform matrix multiplication (not a loop) to compute $\\hat y$ (```yhat```) for all observations here.  Hint - determine the desired shape of the output and make the correct matrix multiplication before calling ```dot()```.  You may find it necessary to use ```numpy```'s transpose operator (```.T```) on one or both matrices :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41f038c472d620df61f835e8310ae2ff",
     "grade": false,
     "grade_id": "cell-4f9c81fe7b1fc5ff",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "#estimate yhat for all 5 datapoints\n",
    "#----------------------------------------------\n",
    "\n",
    "def estimate( beta=np.zeros((1,2)), X=np.ones((5,2))):\n",
    "    \n",
    "    yhat = np.array([[]])  #placeholder for yhat (which is a 5 x 1 array of floats)\n",
    "    #STUDENT CODE - Insert code for computing yhat here:\n",
    "    #----------------------------------------------\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    #----------------------------------------------\n",
    "    return yhat\n",
    "\n",
    "\n",
    "yhat = estimate(beta,X)\n",
    "\n",
    "print('yhat','\\n',  yhat,'\\n')\n",
    "#print(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "591e499f5b376ab6c2fa9bd30c94a963",
     "grade": false,
     "grade_id": "cell-290c741f49ca4961",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Next, compute the residual error terms which are the difference between each guessed ```yhat``` and the label value for that observation (```y```)\n",
    "\n",
    "STUDENT CODE - insert your code to compute the residuals below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6da80f286b7d08f76e79b3e0442af8ca",
     "grade": false,
     "grade_id": "cell-817df274a1b7d590",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "#----------------------------------------------\n",
    "\n",
    "def compute_errors(yhat, y):\n",
    "    '''find the difference betwen predicted and truth'''\n",
    "    ydiff = None  #insert code to compute ydiff which will be a 5x1 matrix (one error term per prediction error on y)\n",
    "    #----------------------------------------------\n",
    "    #find the difference betwen predicted and truth \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    #----------------------------------------------\n",
    "    return ydiff\n",
    "\n",
    "residuals = compute_errors(yhat, y)\n",
    "print('yhat: ', '\\n', yhat, '\\n')\n",
    "print('y: ', '\\n', y, '\\n')\n",
    "print('Residuals: ', '\\n', residuals, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "115ba567f50bf957b2af89be099a2a80",
     "grade": false,
     "grade_id": "cell-54f5355de496d819",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "When performing evaluation of the performance of several models we often like to compare single scalar values rather than comparing sets of residual errors from each model.   Common measures include Residual Sum of Squares (RSS), Mean Squared Error (MSE), Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE).\n",
    "\n",
    "If you dont know the formulas for how to compute each of these scalar values, look them up before you implement them by hand (dont use built in code or packages to do this... practice writing them by hand)\n",
    "\n",
    "*Extra challenges*:\n",
    "* Can you write the formula for RSS as a (```numpy```) matrix multiplication instead of a loop?\n",
    "* Can you write the formula for MSE as a function operating on RSS? \n",
    "* Can you write the formula for RMSE as a function operating on MSE?\n",
    "\n",
    "\n",
    "STUDENT CODE - insert your code for determining RSS (```rss```), MSE (```mse```) and RMSE (```rmse```) here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "af99d30f1a338c73cdabb24f42cf784d",
     "grade": false,
     "grade_id": "cell-0ca1f47500d35517",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "# Residual Sum of Squares RSS = the sum of the squared error terms \n",
    "rss = None #placeholder for RSS which will be a scalar float\n",
    "\n",
    "# Mean Squared Error MSE\n",
    "mse = None  #placeholder for MSE which will be a scalar float\n",
    "\n",
    "# Root Mean Squared Error RMSE\n",
    "rmse =  None  #placeholder for RMSE which will be a scalar float\n",
    "\n",
    "# Mean Absolute Error MAE\n",
    "mae =  None  #placeholder for RMSE which will be a scalar float\n",
    "\n",
    "#----------------------------------------------\n",
    "\n",
    "def compute_rss(residuals):\n",
    "    '''returns the scalar sum of squared errors '''\n",
    "    rss = None\n",
    "    #----------------------------------------------\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    #----------------------------------------------\n",
    "    return rss\n",
    "\n",
    "def compute_mse(residuals):\n",
    "    '''returns the scalar mean of squared errors '''\n",
    "    mse = None\n",
    "    #----------------------------------------------\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    #----------------------------------------------\n",
    "    return mse\n",
    "\n",
    "def compute_rmse(residuals):\n",
    "    '''returns the square root of the mean of squared errors '''\n",
    "    rmse = None\n",
    "    #----------------------------------------------\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    #----------------------------------------------\n",
    "    return rmse\n",
    "\n",
    "def compute_mae(residuals):\n",
    "    '''returns the mean of the absolute value of the errors '''\n",
    "    mae = None\n",
    "    #----------------------------------------------\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    #----------------------------------------------\n",
    "    return mae\n",
    "    \n",
    "    \n",
    "    \n",
    "rss = compute_rss(residuals)\n",
    "mse = compute_mse(residuals)\n",
    "rmse = compute_rmse(residuals)\n",
    "mae = compute_mae(residuals)\n",
    "    \n",
    "print()\n",
    "print('Residuals: \\n', residuals, '\\n')\n",
    "print('RSS: ', rss, '\\n')\n",
    "print('MSE: ', mse, '\\n')\n",
    "print('RMSE: ',rmse, '\\n')\n",
    "print('MAE: ',mae, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3eef9226ac0336c16f169850bf747b81",
     "grade": false,
     "grade_id": "cell-3a973bdf6221a1d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Notice that all the quantiative performance measures are positive.  Also notice that RMSE is in units of the original score, as is MAE, allowing easy-to understand comparisons.  However, RMSE is more affected by large errors in ydiff and less affected by smaller errors in ydiff than MAE.  Quantitative measures of error which involve a squaring term (e.g. RSS, MSE, RMSE) are subject to this exacerbation-of-larger-error-values behavior and models which minimize these squared error terms can be greatly influenced by outliers.\n",
    "\n",
    "Can you pick a better beta using these error values?\n",
    "\n",
    "Select a different value for ```newbeta``` in the code cell below and see how the new ```newbeta``` affects both the line and the performance measures.   Choose one of the two measures - RMSE or MAE and see how low you can get it to go by repeatedly choosing a better value for ```newbeta``` and rerunning the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db4a228c35bad943dd1b0d592555c863",
     "grade": false,
     "grade_id": "cell-298e3fceebd4bbfe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "new_beta = np.zeros((1,2))  #placeholder for your the value of newbeta\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "#plot the graph\n",
    "newfig = generate_plot(X,y,[beta, new_beta],[\"previous beta line\",\"new beta line\"],myfig)\n",
    "#compute the new error terms\n",
    "new_residuals = compute_errors(estimate(new_beta,X),y)\n",
    "\n",
    "new_rss = compute_rss(new_residuals)\n",
    "new_mse = compute_mse(new_residuals)\n",
    "new_rmse = compute_rmse(new_residuals)\n",
    "new_mae = compute_mae(new_residuals)\n",
    "    \n",
    "print()\n",
    "print('new_residuals: \\n', new_residuals, '\\n')\n",
    "print('RSS: ', rss, '\\n')\n",
    "print('MSE: ', mse, '\\n')\n",
    "print('RMSE: ',rmse, '\\n')\n",
    "print('MAE: ',mae, '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a030ab079c050fa17ab28f02b407465d",
     "grade": false,
     "grade_id": "cell-075af3deba59b294",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Great!  Lets recap.  So far you've:\n",
    "* Guessed some parameters (```beta```) for a simple linear regression model. \n",
    "* Plotted a line through the data so you could see what your beta-generated line would look like\n",
    "* Used your model to compute estimates for the final exam scores from the pretest scores.\n",
    "* Determined how much each of those predictions was off, using residuals\n",
    "* Computed several measures of performance by which you could compare models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c5685e3d392fffe2c9179aa92e26aaa0",
     "grade": false,
     "grade_id": "cell-39bba5854d8e140d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "we've got a working model and we can Lets take a look at its prediction for a new student entering the class with a pre-test score of 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5c85d4f85e943dabf127a33b7d753ac",
     "grade": false,
     "grade_id": "cell-4eca524f6266fe6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "STUDENT CODE - insert your code for predicting the final exam score for a student $i$ who's pretest is $X_i$ = 80 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6c7a4220970b94d701c361e93459a11",
     "grade": false,
     "grade_id": "cell-e6f0ab4d5143364e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#----------------------------------------------\n",
    "#make prediction on test score of 80\n",
    "t = np.array([[1., 80.]]) # this array holds the test point observation\n",
    "ythat = None #placeholder for the predicted final exam score at this test point\n",
    "#----------------------------------------------\n",
    "\n",
    "def predict(beta, t):\n",
    "    yhat = np.array([[0.]]) #placeholder for prediction\n",
    "    #----------------------------------------------\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    #----------------------------------------------\n",
    "    return yhat\n",
    "\n",
    "yhat = predict(beta,t)\n",
    "yhat_new = predict(new_beta,t)\n",
    "    \n",
    "print('Previous Prediction at 80 is', yhat, '\\n')\n",
    "print('New Prediction at 80 is', yhat_new, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "68c63b06485d3287f5d952acf9e309d2",
     "grade": false,
     "grade_id": "cell-444064e8047e6938",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Hopefully your prediction using your search for a better (```beta```) based on reducing squared error yielded something closer to the right answer.\n",
    "Lets see how well you did.\n",
    "\n",
    "In this next step we are going to use the closed form of Ordinary Least Squares (OLS) Regression to compute the actual best intercept and slope.\n",
    "Then we can compare how you did to the OLS \"ideal\" solution.\n",
    "The comparison will include both a numerical comparison and a visual comparison.  Note that the visual comparison may not reveal\n",
    "the differences between your best solution the OLS solution if they are very close."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65c3174e152db88c802704e27bcecbb7",
     "grade": false,
     "grade_id": "cell-ee4c9c47efdfdf4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#add the ideal line to a graph based on linear least squares fit\n",
    "intercept, slope = np.linalg.lstsq(X, y)[0]\n",
    "ideal_beta = np.array([[intercept,slope]])\n",
    "# ideal_x,ideal_y=computeline(intercept,slope,0,100)\n",
    "# plt.plot(ideal_x,ideal_y,ls='--',c='b')\n",
    "yhat_ideal = predict(ideal_beta,t)\n",
    "\n",
    "print('Your Prediction at 80 is', yhat_new, '\\n')\n",
    "print('Ideal Prediction at 80 is', yhat_ideal, '\\n')\n",
    "print('Difference is ',yhat_ideal-yhat_new, '\\n')\n",
    "\n",
    "newfig = generate_plot(X,y,[beta, new_beta, ideal_beta],\n",
    "                       [\"previous beta line\",\"new beta line\",\"ideal solution\"],myfig)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
